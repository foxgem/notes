---
pubDatetime: 2025-01-29T11:04:54Z
title: "Exploring Prompt Optimization"
slug: c4c4362b300dd006a18a29e3e8b0fa31
tags:
  - prompt optimization
  - llms
  - meta-prompting
  - few-shot prompting
  - evolutionary optimization
---

**关键字:** Prompt Optimization, LLMs, Meta-prompting, Few-shot prompting, Evolutionary Optimization

**概述:**
本文深入探讨了五种不同的提示优化方法，并使用五个不同的数据集对这些方法进行了基准测试。研究结果表明，提示优化在模型缺乏领域知识的任务中最为有效，并且可以显著提高准确性。文章还比较了三种不同的模型（O1、GPT-4o 和 Claude-3.5-Sonnet）在提示优化方面的表现，并推荐 Claude-3.5-Sonnet 作为首选的优化模型。此外，文章还强调了提示优化作为一种长期记忆形式的潜力，以及它在构建更强大、更智能的 LLM 应用中的重要性。文章最后还提供了实验的复现链接，并对训练动态进行了分析。

**分节阅读:**

*   **What we tested:**
    *   文章测试了五种流行的提示优化方法，包括少样本提示、元提示、带反思的元提示、提示梯度和进化优化。
    *   这些方法在三个模型（O1、GPT-4 和 Claude-3.5-Sonnet）和五个代表常见任务的数据集上进行了测试。
    *   主要目的是回答提示优化何时效果最佳、哪些前沿模型适合提示优化以及哪些算法最可靠等问题。

*   **Algorithms:**
    *   文章详细介绍了五种提示优化算法，包括少样本提示、元提示、带反思的元提示、提示梯度和进化优化。
    *   少样本提示使用训练示例作为预期行为的演示，而元提示使用 LLM 分析和改进提示。
    *   进化优化通过受控突变探索提示空间，并结合文本梯度方法和全局更新来克服局部最优。

*   **Datasets:**
    *   文章创建了五个数据集用于基准测试，包括支持电子邮件路由（3个和10个分配者）、多语言数学、简单电子邮件助手和古怪电子邮件助手。
    *   这些数据集旨在测试不同场景下的提示优化效果，包括领域知识缺乏、隐藏模式和细微偏好。
    *   多语言数学数据集包含一个隐藏模式，即目标语言由单词问题的主题决定。

*   **Results:**
    *   文章展示了在五个数据集上使用不同模型和算法的实验结果，并使用柱状图和置信区间来可视化结果。
    *   结果表明，提示优化在模型缺乏领域知识的任务中效果最佳，并且进化算法通常优于其他方法。
    *   Claude-3.5-Sonnet 在提示优化方面表现更可靠，而 O1 的方差较高。

*   **What We Learned:**
    *   元提示对于发现数据中的规则或偏好非常有用，但对于传达细微的偏好则不太有效。
    *   少样本提示和指令调整相结合可以提供互补的改进，少样本示例传达更多信息，而提示优化可以根据现有性能进行更有针对性的改进。
    *   元提示不会赋予模型新的能力，它只能指导模型如何表现，而不能解锁更强大的推理能力。

*   **Beyond evals:**
    *   文章强调了使用可验证结果的数据集进行优化的重要性，并指出模糊或不可靠的指标会导致提示变得更糟。
    *   LangSmith 可以帮助团队系统地评估 LLM 应用程序，并使用评估数据集来驱动系统改进。
    *   数据、指标和学习形成了一个闭环，可以实现系统的改进。

*   **Prompt optimization as long-term memory:**
    *   文章将提示优化视为一种长期记忆形式，它可以捕获“始终在线”的行为模式。
    *   提示优化将信息直接存储在代理的提示中，确保它们影响每个决策，这对于存储核心模式非常有用。
    *   记忆的“学习和改进”过程与传统的提示优化非常相似，只是更新的计划方式和存储位置略有不同。

*   **Why this matters:**
    *   LLM 驱动的提示优化可以系统地改进提示，并自动化许多手动猜测和检查的过程。
    *   提示优化不是万能的，它只是改进 LLM 应用程序的工具包中的一个工具。
    *   文章计划将这些见解直接集成到 LangSmith 中，以帮助团队超越手动提示工程。

*   **Reproduction:**
    *   文章提供了实验的复现链接，以便读者可以重现实验结果。

*   **Appendix:**
    *   文章提供了每个数据集的开发集训练动态图表，以展示不同算法如何适应数据集。
    *   文章还比较了不同算法和模型生成的最终提示，以了解优化器实际学习修改的内容。

**相关工具:**

*   [DSPy](https://dspy.ai/?ref=blog.langchain.dev)
*   [promptim](https://dspy.ai/?ref=blog.langchain.dev)
*   [LangSmith](https://docs.smith.langchain.com/?ref=blog.langchain.dev)

**参考文献:**

*   [Automatic Prompt Optimization](https://arxiv.org/abs/2305.03495?ref=blog.langchain.dev)
*   [PhaseEvo](https://arxiv.org/abs/2402.11347?ref=blog.langchain.dev)
*   [Opsahl Ong, et. al.](https://arxiv.org/abs/2406.11695?ref=blog.langchain.dev)
*   [Wan, et. al](https://arxiv.org/pdf/2406.15708?ref=blog.langchain.dev)
*   [Wilson score interval](https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval?ref=blog.langchain.dev)

**原文链接:** https://blog.langchain.dev/exploring-prompt-optimization/


source: https://blog.langchain.dev/exploring-prompt-optimization/