---
pubDatetime: 2025-01-28T01:00:07Z
title: "Over 700 million events/second: How we make sense of too much data"
slug: ffbaf0f2aa203df35b6b469a1a6ad106
tags:
  - 数据管道
  - 下采样
  - horvitz-thompson 估计器
  - 置信区间
  - 自适应采样
---

**语言:** 中文

**关键字:** 数据管道, 下采样, Horvitz-Thompson 估计器, 置信区间, 自适应采样

**概述:**
Cloudflare 的数据管道每秒处理超过 7 亿个事件，为了应对如此庞大的数据量，文章介绍了 Cloudflare 如何通过下采样技术在数据管道的各个阶段控制数据丢失，并使用 Horvitz-Thompson 估计器从下采样数据中提取有意义的分析结果。文章还强调了在采样过程中可能出现的错误，以及如何通过自适应采样和置信区间来提高分析的准确性。Cloudflare 通过这些技术，确保即使在数据量巨大且系统过载的情况下，也能为客户提供可靠的分析服务。

**分节阅读:**

*   **Dropping data to retain information**
    *   为了在数据量过大时保留有价值的信息，Cloudflare 使用下采样技术，在数据管道的各个阶段控制数据丢失。
    *   Logfwdr 通过为每个数据流分配权重并应用最大最小公平性来管理缓冲区，确保在缓冲区饱和时公平地分配内存。
    *   Cloudflare 采用“无底缓冲区”方法，通过合并最小下采样的批次来均匀地进行下采样，并使用预先下采样来降低重新压缩的成本。

*   **Extracting value from downsampled data**
    *   Cloudflare 使用 Horvitz-Thompson 估计器来从下采样数据中推导出分析结果，并计算估计值的方差，从而构建置信区间。
    *   通过 Poisson 采样，可以简化方差估计器的计算，并为 SUM、COUNT 和 AVG 等指标提供准确的估计。
    *   为了解决 AVG 估计中未知总体大小的问题，Cloudflare 使用 Bonferroni 方法构建同时置信区间，从而提高分析的可靠性。

*   **Sampling is easy to screw up**
    *   Cloudflare 在内部仪表板上使用置信区间时发现了一个系统性错误，原因是 Logreceiver 使用了系统采样而不是随机采样。
    *   系统采样导致估计值出现偏差，因为在批次中，第一个响应往往比平均值大，从而扭曲了整体的估计。
    *   通过在采样前对数据进行洗牌，Cloudflare 解决了这个问题，并确保了估计值与真实值的一致性。

*   **Using Cloudflare's analytics APIs to query sampled data**
    *   Cloudflare 的分析 API 已经使用采样数据来支持大多数分析数据集，例如 Workers Analytics Engine 暴露了采样间隔。
    *   GraphQL API 中，基于采样数据的数据节点也暴露了采样间隔，并且 Cloudflare 正在努力在 GraphQL API 中暴露置信区间。
    *   通过 GraphQL 查询，用户可以获取估计值和 95% 置信区间，以及样本大小，从而更好地理解分析结果的准确性。

**相关工具:**

*   [Logs](https://developers.cloudflare.com/logs/)
*   [Analytics](https://developers.cloudflare.com/analytics/)
*   [Workers Analytics Engine](https://developers.cloudflare.com/analytics/analytics-engine/)

**参考文献:**

*   [2018 data pipeline blog post](https://blog.cloudflare.com/http-analytics-for-6m-requests-per-second-using-clickhouse/)
*   [blog post](https://blog.cloudflare.com/cloudflare-incident-on-november-14-2024-resulting-in-lost-logs/)
*   [max-min fairness](https://en.wikipedia.org/wiki/Max-min_fairness)
*   [max-heap](https://en.wikipedia.org/wiki/Heap_\(data_structure\))
*   [reservoir sampling](https://en.wikipedia.org/wiki/Reservoir_sampling)
*   [Horvitz-Thompson estimator](https://en.wikipedia.org/wiki/Horvitz%E2%80%93Thompson_estimator)
*   [paper](https://www.stat.cmu.edu/~brian/905-2008/papers/Horvitz-Thompson-1952-jasa.pdf)
*   [confidence intervals](https://en.wikipedia.org/wiki/Confidence_interval)
*   [Poisson sampling](https://en.wikipedia.org/wiki/Poisson_sampling)
*   [Bernoulli trial](https://en.wikipedia.org/wiki/Bernoulli_trial)
*   [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem)
*   [Bonferroni method](https://www.sciencedirect.com/topics/mathematics/bonferroni-method)
*   [sample interval](https://developers.cloudflare.com/analytics/analytics-engine/sql-api/#sampling)
*   [Adaptive](https://developers.cloudflare.com/analytics/graphql-api/sampling/#adaptive-sampling)

**原文链接:** https://blog.cloudflare.com/how-we-make-sense-of-too-much-data/?utm_campaign=cf_blog&utm_content=20250127&utm_medium=organic_social&utm_source=twitter/


source: https://blog.cloudflare.com/how-we-make-sense-of-too-much-data/?utm_campaign=cf_blog&utm_content=20250127&utm_medium=organic_social&utm_source=twitter/